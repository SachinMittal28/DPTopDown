{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://csmining.org/index.php/r52-and-r8-of-reuters-21578.html\n",
    "#https://web.stanford.edu/class/cs124/lec/naivebayes.pdf\n",
    "\n",
    "import numpy\n",
    "import math\n",
    "import nltk\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from nltk import FreqDist\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "def initialize_train():\n",
    "    train_url = \"http://csmining.org/tl_files/Project_Datasets/r8%20r52/r8-train-all-terms.txt\"\n",
    "    train_doc = urlopen(train_url).read() \n",
    "    train_doc = train_doc.decode(\"utf-8\")\n",
    "    return train_doc #returns all docs as one String\n",
    "\n",
    "def initialize_test():\n",
    "    test_url = \"http://csmining.org/tl_files/Project_Datasets/r8%20r52/r8-test-all-terms.txt\"\n",
    "    test_doc = urlopen(test_url).read() \n",
    "    test_doc = test_doc.decode(\"utf-8\")\n",
    "    return test_doc #returns all docs as one String\n",
    "\n",
    "\n",
    "\n",
    "def CountAllCategories(doc):\n",
    "    pattern='[A-z]*-*[A-z]*\\t'\n",
    "    f = re.findall(pattern,doc)\n",
    "    return Counter(f) #returns dictionary \n",
    "\n",
    "\n",
    "\n",
    "test_doc = initialize_test()      # all docs as one String\n",
    "train_doc = initialize_train()    # all docs as one String\n",
    "\n",
    "train_vocab = sorted(list(set(word_tokenize(train_doc))))\n",
    "\n",
    "pattern1 = r\"([\\w+]*[-]*[\\w+]*[\\t])(.*)(\\b)\"\n",
    "test_docs = re.findall(pattern1,test_doc) #note that categories are accompanied with \"/t\" i.e. \"earn\" is NOT a category but \"earn\\t\" is\n",
    "train_docs = re.findall(pattern1,train_doc) #all docs is in one list now, list of tuples, each tuple is one doc = [(class, document),(class, document),(class, document)]\n",
    "\n",
    "def CalculateClassProb():\n",
    "    probabilities = {}\n",
    "    totalDocs = sum(Dict4CountOfCategories.values())\n",
    "    for category in Dict4CountOfCategories.keys():\n",
    "        probabilities[category] = Dict4CountOfCategories[category]/totalDocs\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "LikelihoodProbabilities = {}\n",
    "\n",
    "def appendGivenCategoryDocsIntoOne(docs,cat):\n",
    "    s=\"\"\n",
    "    for doc in docs:\n",
    "        if (doc[0] == cat):\n",
    "            s=s+doc[1]\n",
    "    return s\n",
    "\n",
    "trainDocumentCategoryWise={}\n",
    "\n",
    "for c_j in Dict4CountOfCategories.keys():\n",
    "    trainDocumentCategoryWise[c_j] = appendGivenCategoryDocsIntoOne(train_docs,c_j)\n",
    "\n",
    "\n",
    "#CountAllCategories(test_doc)\n",
    "#CountAllCategories(train_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'earn\\t': 2840, 'acq\\t': 1596, 'trade\\t': 251, 'ship\\t': 108, 'grain\\t': 41, 'crude\\t': 253, 'interest\\t': 190, 'money-fx\\t': 206}\n"
     ]
    }
   ],
   "source": [
    "Dict4CountOfCategories = dict(CountAllCategories(train_doc))\n",
    "print(Dict4CountOfCategories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'earn\\t': 0.5177757520510483, 'acq\\t': 0.290975387420237, 'trade\\t': 0.04576116681859617, 'ship\\t': 0.019690063810391976, 'grain\\t': 0.00747493163172288, 'crude\\t': 0.046125797629899726, 'interest\\t': 0.03463992707383774, 'money-fx\\t': 0.03755697356426618}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Class_probabilities = CalculateClassProb()\n",
    "print(Class_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def CalculateLikelihoodProb(vocab,DocumentCategoryWise):\n",
    "    aplha_smooth = 1\n",
    "    probabilities = {}\n",
    "    for w_k in train_vocab: #take each word from vocab\n",
    "        for c_j in Dict4CountOfCategories.keys():\n",
    "            n_k = len(re.findall(w_k+\" \",DocumentCategoryWise[c_j]))\n",
    "            n=len(DocumentCategoryWise[c_j])  #total number of words in c_j\n",
    "            probabilities[(w_k,c_j)] = (n_k+aplha_smooth)/(n+aplha_smooth*len(vocab))\n",
    "        #P(word|class)=(word_count_in_class + 1)/(total_words_in_class+total_unique_words_in_all_classes\n",
    "    return probabilities\n",
    "\n",
    "probabilities = CalculateLikelihoodProb(train_vocab,trainDocumentCategoryWise)\n",
    "\n",
    "#print(probabilities)\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "def CalculateLikelihoodProbONDemand(vocab,DocumentCategoryWise,w_k, c_j):\n",
    "    aplha_smooth=1\n",
    "    n_k = len(re.findall(w_k+\" \",DocumentCategoryWise[c_j])) #number of times word occur in all docs with c_j\n",
    "    n=len(DocumentCategoryWise[c_j])  #total number of words in c_j\n",
    "    LikelihoodProbabilities[(w_k,c_j)] = (n_k+aplha_smooth)/(n+aplha_smooth*len(vocab))\n",
    "    return LikelihoodProbabilities[(w_k,c_j)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy -  0.8158976701690269\n",
      "Train Accuracy -  0.8211485870556062\n"
     ]
    }
   ],
   "source": [
    "def get_true_labels(docs):\n",
    "    true_labels = list()\n",
    "    for doc in docs:\n",
    "        true_label = doc[0]\n",
    "        true_labels.append(true_label)\n",
    "    return true_labels\n",
    "\n",
    "\n",
    "def predict_model(docs):\n",
    "    predicted_labels=list()\n",
    "    for doc in docs:\n",
    "        d={}\n",
    "        for c_j in Dict4CountOfCategories.keys():\n",
    "            p=1\n",
    "            for w_k in set(word_tokenize(doc[1])):\n",
    "                if ((w_k,c_j) in probabilities):\n",
    "                    p=p*probabilities[(w_k,c_j)]\n",
    "                else: p = p*CalculateLikelihoodProbONDemand(train_vocab,trainDocumentCategoryWise,w_k,c_j)\n",
    "                #else: p = p*(1/(Dict4CountOfCategories[c_j]+len(train_vocab)))\n",
    "            d[c_j]=p*Class_probabilities[c_j]\n",
    "        predicted_label = max(d, key=d.get)\n",
    "        predicted_labels.append(predicted_label)\n",
    "    return predicted_labels\n",
    "\n",
    "def Calculate_accuracy(true_labels,predicted_labels):\n",
    "    CorrectClassify=0\n",
    "    for i in range(len(true_labels)):\n",
    "        if (predicted_labels[i]==true_labels[i]):\n",
    "                CorrectClassify=CorrectClassify+1\n",
    "    return CorrectClassify/len(true_labels)\n",
    "\n",
    "test_predicted_labels=predict_model(test_docs)\n",
    "train_predicted_labels=predict_model(train_docs)\n",
    "\n",
    "\n",
    "test_true_labels=get_true_labels(test_docs)\n",
    "train_true_labels=get_true_labels(train_docs)\n",
    "\n",
    "\n",
    "print(\"Test Accuracy - \", Calculate_accuracy(test_true_labels,test_predicted_labels))\n",
    "print(\"Train Accuracy - \", Calculate_accuracy(train_true_labels,train_predicted_labels))\n",
    "\n",
    "#using built in method of accuracy-\n",
    "#print(\"Test Accuracy\", metrics.accuracy_score(test_true_labels,test_predicted_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Train - \n",
      "\n",
      "Predicted   acq  crude  earn  grain  interest  money-fx  ship  trade  __all__\n",
      "Actual                                                                       \n",
      "acq        1172      3   406      8         4         0     3      0     1596\n",
      "crude         1    115   135      0         0         0     1      1      253\n",
      "earn         23      4  2800      6         3         1     3      0     2840\n",
      "grain         0      0    19     22         0         0     0      0       41\n",
      "interest      0      0    45      0       145         0     0      0      190\n",
      "money-fx      1      0    75      1        19       110     0      0      206\n",
      "ship          0      0    45      1         0         0    62      0      108\n",
      "trade         0      1   164      0         2         5     1     78      251\n",
      "__all__    1197    123  3689     38       173       116    70     79     5485\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------- \n",
      "\n",
      "Confusion Matrix for Test - \n",
      "\n",
      "Predicted  acq  crude  earn  grain  interest  money-fx  ship  trade  __all__\n",
      "Actual                                                                      \n",
      "acq        503      3   164     16         3         1     5      1      696\n",
      "crude        0     58    59      1         0         0     3      0      121\n",
      "earn         6      0  1075      1         1         0     0      0     1083\n",
      "grain        0      0     3      7         0         0     0      0       10\n",
      "interest     0      0    21      0        59         1     0      0       81\n",
      "money-fx     0      0    33      0         6        48     0      0       87\n",
      "ship         0      1    19      0         0         0    16      0       36\n",
      "trade        0      1    48      4         0         1     1     20       75\n",
      "__all__    509     63  1422     29        69        51    25     21     2189\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_confusionMetrix(true_labels,predicted_labels ):\n",
    "    true_labels=[s.strip() for s in true_labels]\n",
    "    predicted_labels=[s.strip() for s in predicted_labels]\n",
    "    cm =ConfusionMatrix(true_labels, predicted_labels)\n",
    "    print(cm, end=\"\\n\\n\\n\")\n",
    "\n",
    "print(\"Confusion Matrix for Train - \",end=\"\\n\\n\")\n",
    "make_confusionMetrix(train_true_labels,train_predicted_labels )\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------- \",end=\"\\n\\n\")\n",
    "\n",
    "print(\"Confusion Matrix for Test - \",end=\"\\n\\n\")\n",
    "make_confusionMetrix(test_true_labels,test_predicted_labels )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
